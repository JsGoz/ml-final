{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6f5675-0f51-41ba-9bbc-0e531a2106fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Imports\n",
    "# -----------------------------\n",
    "import os\n",
    "import requests\n",
    "import re\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3a96e6c-2225-4e24-8b5d-dec472de2ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpeta creada: C:\\PROY_FINAL_ML\\data/raw\n",
      "Carpeta creada: C:\\PROY_FINAL_ML\\data/processed\n",
      "Carpeta creada: C:\\PROY_FINAL_ML\\models\n",
      "Carpeta creada: C:\\PROY_FINAL_ML\\notebooks\n",
      "Carpeta creada: C:\\PROY_FINAL_ML\\scripts\n",
      "Carpeta creada: C:\\PROY_FINAL_ML\\src/cba\n",
      "\n",
      "✅ Estructura completa en: C:\\PROY_FINAL_ML\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Creacion de la estructura de carpetas\n",
    "# -----------------------------\n",
    "# Ruta base en C:\n",
    "base_path = r\"C:\\PROY_FINAL_ML\"\n",
    "\n",
    "# Estructura de carpetas\n",
    "folders = [\n",
    "    \"data/raw\",\n",
    "    \"data/processed\",\n",
    "    \"models\",\n",
    "    \"notebooks\",\n",
    "    \"scripts\",\n",
    "    \"src/cba\"\n",
    "]\n",
    "\n",
    "for folder in folders:\n",
    "    path = os.path.join(base_path, folder)\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    print(f\"Carpeta creada: {path}\")\n",
    "\n",
    "print(\"\\n✅ Estructura completa en:\", base_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a069e395-d1be-4abe-b382-048035c8edbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando cba_202101.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202101.csv\n",
      "Descargando cba_202102.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202102.csv\n",
      "Descargando cba_202103.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202103.csv\n",
      "Descargando cba_202104.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202104.csv\n",
      "Descargando cba_202107.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202107.csv\n",
      "Descargando cba_202108.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202108.csv\n",
      "Descargando cba_202109.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202109.csv\n",
      "Descargando cba_202111.csv ...\n",
      "✅ Guardado en C:\\PROY_FINAL_ML\\data\\raw\\cba_202111.csv\n",
      "⚡ Ya existe: cba_202201.csv\n",
      "⚡ Ya existe: cba_202202.csv\n",
      "⚡ Ya existe: cba_202203.csv\n",
      "⚡ Ya existe: cba_202204.csv\n",
      "⚡ Ya existe: cba_202205.csv\n",
      "⚡ Ya existe: cba_202206.csv\n",
      "\n",
      "🎯 Descarga completada. Archivos en: C:\\PROY_FINAL_ML\\data\\raw\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Descarga de datasets ACODECO\n",
    "# -----------------------------\n",
    "# Ruta donde guardar los datos\n",
    "raw_path = r\"C:\\PROY_FINAL_ML\\data\\raw\"\n",
    "os.makedirs(raw_path, exist_ok=True)\n",
    "\n",
    "# Diccionario con nombre de archivo -> URL\n",
    "files_urls = {\n",
    "    # 2020\n",
    "#    \"cba_202002.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/51365504-c417-48b6-b5ed-9f4f091bb070/download/cbapromsector_feb2020.csv\",\n",
    "#    \"cba_202003.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/f154b997-2542-4609-b14a-c1b713c40c22/download/cba_mar2020.csv\",\n",
    "#    \"cba_202006.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/b3dad7ac-2660-47f8-b947-a2f84647f9df/download/cba_junio2020.csv\",\n",
    "#    \"cba_202007.xls\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/4b0f182d-74af-4b8d-a75b-a76b859e1159/download/cba_julio2020.xls\",\n",
    "#    \"cba_202008.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/c6f0ae30-e8ff-4ffc-bb78-7f22e9d3699f/download/cba_agosto2020.csv\",\n",
    "#    \"cba_202009.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/7a19023b-3acf-43aa-bc55-eb00787b9deb/download/cba_sept2020.csv\",\n",
    "#    \"cba_202010.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/7bad8bfe-c9ca-4c66-af06-762cd5a07772/download/cba_octubre2020.csv\",\n",
    "#    \"cba_202011.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/212a9ea3-ea32-4be7-9987-2e2efe61e359/download/cbacsv_nov2020.csv\",\n",
    "#    \"cba_202012.csv\": \"https://www.datosabiertos.gob.pa/dataset/eb1eb8d3-402d-40ce-9bbd-91c4760b42af/resource/81fd99d7-f2c3-4e97-9f63-66c6e1bb2b14/download/cba_dic2020.csv\",\n",
    "\n",
    "    # 2021\n",
    "    \"cba_202101.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/00012413-8c41-4ddb-874e-a7970fcd62ff/download/cba_enero2021-csv.csv\",\n",
    "    \"cba_202102.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/150ae2ee-7f6a-4af6-9175-c95435fd3491/download/cba_febrero2021-csv.csv\",\n",
    "    \"cba_202103.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/3f88072c-6d36-4aae-a237-5bf44ad64cec/download/cba_marzo_csv2021.csv\",\n",
    "    \"cba_202104.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/604dac83-9aef-4588-8c6a-366e23dd7790/download/cba_abril2021csv.csv\",\n",
    "    \"cba_202107.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/55d7b5c0-d72d-4713-b45f-8bf5bc345a3b/download/cba_julio2021-csv.csv\",\n",
    "    \"cba_202108.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/24076062-f86c-4d5a-8726-b6074b2676c0/download/cba_ago2021.csv\",\n",
    "    \"cba_202109.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/66df3d19-db9d-4a56-9619-cb4b393fcc3c/download/cba_sept2021csv.csv\",\n",
    "    \"cba_202111.csv\": \"https://www.datosabiertos.gob.pa/dataset/720d6cd6-d55b-4b01-a090-cf84c51f4324/resource/21c97728-6fd8-4b38-a3b0-7dd3d5a7d880/download/cba_nov2021.csv\",\n",
    "\n",
    "    # 2022\n",
    "    \"cba_202201.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/69b29e97-1ca4-4d2b-b02c-ba87f888a562/download/cba_ene2022.csv\",\n",
    "    \"cba_202202.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/f18e85fb-2df4-4eec-b432-89ce7373dfc7/download/cba_feb2022.csv\",\n",
    "    \"cba_202203.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/f4a9ff0e-51b4-410e-b11f-5395bfbf2258/download/cba_marzo2022csv.csv\",\n",
    "    \"cba_202204.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/8218c25d-5b13-446b-a711-7cb7abf00ab4/download/cba_abril2022_csv.csv\",\n",
    "    \"cba_202205.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/f9f97559-62b1-4348-b312-667e96f79901/download/cbamayo2022.csv\",\n",
    "    \"cba_202206.csv\": \"https://www.datosabiertos.gob.pa/dataset/804a1e66-64a7-4720-aa11-bb92c976b17d/resource/27162758-05d6-44a1-b7c3-4012cec61957/download/cba_junio2022.csv\",\n",
    "}\n",
    "\n",
    "# Descargar cada archivo\n",
    "for fname, url in files_urls.items():\n",
    "    path = os.path.join(raw_path, fname)\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Descargando {fname} ...\")\n",
    "        r = requests.get(url)\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(f\"✅ Guardado en {path}\")\n",
    "    else:\n",
    "        print(f\"⚡ Ya existe: {fname}\")\n",
    "\n",
    "print(\"\\n🎯 Descarga completada. Archivos en:\", raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b51f3b4-fc01-4cb6-ba38-555e85393c6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivos encontrados (14):\n",
      " - cba_202101.csv\n",
      " - cba_202102.csv\n",
      " - cba_202103.csv\n",
      " - cba_202104.csv\n",
      " - cba_202107.csv\n",
      " - cba_202108.csv\n",
      " - cba_202109.csv\n",
      " - cba_202111.csv\n",
      " - cba_202201.csv\n",
      " - cba_202202.csv\n",
      " - cba_202203.csv\n",
      " - cba_202204.csv\n",
      " - cba_202205.csv\n",
      " - cba_202206.csv\n",
      "Dimensiones unificadas: (828, 163)\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# unificar Datasets\n",
    "# -----------------------------\n",
    "# Rutas\n",
    "raw_path = r\"C:\\PROY_FINAL_ML\\data\\raw\"\n",
    "processed_path = r\"C:\\PROY_FINAL_ML\\data\\processed\"\n",
    "os.makedirs(processed_path, exist_ok=True)\n",
    "\n",
    "# Listar archivos CSV\n",
    "files = glob.glob(os.path.join(raw_path, \"*.csv\"))\n",
    "print(f\"Archivos encontrados ({len(files)}):\")\n",
    "for f in files:\n",
    "    print(\" -\", os.path.basename(f))\n",
    "\n",
    "# Función para extraer year, month y YYYYMM desde nombre de archivo tipo cba_202201.csv\n",
    "def extraer_anio_mes(filename):\n",
    "    match = re.search(r\"(\\d{6})\", filename)  # Busca 6 dígitos consecutivos\n",
    "    if match:\n",
    "        yyyymm = match.group(1)\n",
    "        year = int(yyyymm[:4])\n",
    "        month = int(yyyymm[4:])\n",
    "        return year, month, yyyymm\n",
    "    return None, None, None\n",
    "\n",
    "# Leer y unificar archivos\n",
    "dfs = []\n",
    "\n",
    "for file_path in files:\n",
    "    filename = os.path.basename(file_path)\n",
    "    try:\n",
    "        # Leer CSV sin cabecera primero\n",
    "        df_raw = pd.read_csv(file_path, encoding=\"latin1\", header=None, on_bad_lines=\"skip\", index_col=False)\n",
    "        \n",
    "        # Detectar fila que será cabecera (buscamos 'producto' o similar)\n",
    "        header_row = 0\n",
    "        for i, row in df_raw.iterrows():\n",
    "            if any(\"producto\" in str(c).lower() for c in row):\n",
    "                header_row = i\n",
    "                break\n",
    "        \n",
    "        # Leer de nuevo con cabecera correcta\n",
    "        df = pd.read_csv(file_path, encoding=\"latin1\", header=header_row, on_bad_lines=\"skip\", index_col=False)\n",
    "\n",
    "        # Columnas de seguimiento\n",
    "        df[\"source_file\"] = filename\n",
    "\n",
    "        # Extraer year, month y YYYYMM\n",
    "        year, month, yyyymm = extraer_anio_mes(filename)\n",
    "        df[\"year\"] = year\n",
    "        df[\"month\"] = month\n",
    "        df[\"anio_mes\"] = yyyymm\n",
    "\n",
    "        # Convertir todo a string para evitar errores Parquet\n",
    "        for col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "        dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error procesando {filename}: {e}\")\n",
    "        continue\n",
    " \n",
    "# Concatenar y guardar\n",
    "if dfs:\n",
    "    df_all = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"Dimensiones unificadas:\", df_all.shape)\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No se pudo unificar ningún CSV.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4b31527-1302-4b4d-bc12-af4aa30a08ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones sin columnas vacías: (59, 95)\n",
      "Dimensiones después de limpieza: (50563, 8)\n",
      "                     producto        medida     source_file  year month  \\\n",
      "1            bistec de cinta   1 kilogramos  cba_202101.csv  2021     1   \n",
      "3   carne para sopa costilla   1 kilogramos  cba_202101.csv  2021     1   \n",
      "4                puerco liso   1 kilogramos  cba_202101.csv  2021     1   \n",
      "5                pulpa negra   1 kilogramos  cba_202101.csv  2021     1   \n",
      "7  pechuga de pollo con piel   1 kilogramos  cba_202101.csv  2021     1   \n",
      "\n",
      "  anio_mes            establecimiento  precio  \n",
      "1   202101  casa_de_la_carne_cangrejo    4.96  \n",
      "3   202101  casa_de_la_carne_cangrejo    4.70  \n",
      "4   202101  casa_de_la_carne_cangrejo    7.80  \n",
      "5   202101  casa_de_la_carne_cangrejo    8.89  \n",
      "7   202101  casa_de_la_carne_cangrejo    4.11  \n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Limpieza de Datos\n",
    "# -----------------------------\n",
    "# Eliminar columnas vacías\n",
    "\n",
    "df_all = df_all.dropna(axis=1, how=\"all\")\n",
    "print(\"Dimensiones sin columnas vacías:\", df.shape)\n",
    "\n",
    "# Normalizar nombres de columnas\n",
    "df_all.columns = (\n",
    "    df_all.columns.astype(str)\n",
    "              .str.strip()\n",
    "              .str.lower()\n",
    "              .str.replace(\" \", \"_\")\n",
    "              .str.replace(r\"[^a-z0-9_áéíóúñ]\", \"\", regex=True)  # mantener tildes y ñ\n",
    ")\n",
    "\n",
    "# Wide → Long (melt) -- reformatea la tabla para eliminar el tipo matriz\n",
    "id_vars = [\"producto\", \"medida\", \"source_file\", \"year\", \"month\", \"anio_mes\"]\n",
    "value_vars = [c for c in df_all.columns if c not in id_vars]\n",
    "\n",
    "df_long = df_all.melt(\n",
    "    id_vars=id_vars,\n",
    "    value_vars=value_vars,\n",
    "    var_name=\"establecimiento\",\n",
    "    value_name=\"precio\"\n",
    ")\n",
    "\n",
    "# Limpieza de texto quitar caracteres especiales (mantener tildes y ñ)\n",
    "def limpiar_texto(x):\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    x = str(x).strip().lower()\n",
    "    x = re.sub(r\"[^a-z0-9áéíóúñ\\s\\._-]\", \"\", x)   # quitamos símbolos raros\n",
    "    x = re.sub(r\"\\s+\", \" \", x)                    # colapsar espacios múltiples\n",
    "    return x\n",
    "\n",
    "cols_texto = [\"producto\", \"medida\", \"establecimiento\"]\n",
    "for col in cols_texto:\n",
    "    if col in df_long.columns:\n",
    "        df_long[col] = df_long[col].map(limpiar_texto)\n",
    "\n",
    "# Convertir precios a numérico\n",
    "df_long[\"precio\"] = (\n",
    "    df_long[\"precio\"].astype(str)\n",
    "                     .str.replace(\",\", \".\", regex=False)\n",
    "                     .str.extract(r\"(\\d+\\.?\\d*)\")[0]\n",
    "                     .astype(float)\n",
    ")\n",
    "\n",
    "\n",
    "# Eliminar nulos y precios <= 0\n",
    "df_long = df_long.dropna(subset=[\"producto\", \"precio\"])\n",
    "df_long = df_long[df_long[\"precio\"] > 0]\n",
    "\n",
    "print(\"Dimensiones después de limpieza:\", df_long.shape)\n",
    "print(df_long.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "846df338-725e-41e2-876b-e9d3939d77ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Imputacion de valores Faltantes\n",
    "# -----------------------------\n",
    "def rellenar_periodos_faltantes(df, fecha_col=\"anio_mes\", freq=\"MS\"):\n",
    "    df = df.copy()\n",
    "    df[fecha_col] = pd.to_datetime(df[fecha_col].astype(str), format=\"%Y%m\")\n",
    "\n",
    "    # Crear todas las combinaciones posibles\n",
    "    all_fechas = pd.date_range(df[fecha_col].min(), df[fecha_col].max(), freq=freq)\n",
    "    all_productos = df[\"producto\"].unique()\n",
    "    all_establecimientos = df[\"establecimiento\"].unique()\n",
    "\n",
    "    idx = pd.MultiIndex.from_product(\n",
    "        [all_productos, all_establecimientos, all_fechas],\n",
    "        names=[\"producto\", \"establecimiento\", fecha_col]\n",
    "    )\n",
    "\n",
    "    df_full = (\n",
    "        df.set_index([\"producto\", \"establecimiento\", fecha_col])\n",
    "          .reindex(idx)\n",
    "          .reset_index()\n",
    "    )\n",
    "\n",
    "    return df_full\n",
    "\n",
    "def imputar_por_interpolacion(df, col_target=\"precio\", grupo=[\"producto\", \"establecimiento\"]):\n",
    "    df = df.copy()\n",
    "    df[col_target] = (\n",
    "        df.groupby(grupo)[col_target]\n",
    "          .transform(lambda x: x.interpolate(method=\"linear\"))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "df_long_completo = rellenar_periodos_faltantes(df_long)\n",
    "df_long_completo[\"anio_mes\"].dt.to_period(\"M\").value_counts().sort_index()\n",
    "df_interp = imputar_por_interpolacion(df_long_completo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8b1abd3-9712-4b63-9acb-967efaa142db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Archivos exportados:\n",
      "- C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.csv\n",
      "- C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.xlsx\n",
      "- C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.parquet\n"
     ]
    }
   ],
   "source": [
    "# Guardar limpio para descargar\n",
    "output_csv = r\"C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.csv\"\n",
    "output_excel = r\"C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.xlsx\"\n",
    "output_parquet = r\"C:\\PROY_FINAL_ML\\data\\processed\\cba_clean.parquet\"\n",
    "\n",
    "# Exportar en varios formatos\n",
    "df_interp.to_csv(output_csv, index=False, encoding=\"utf-8-sig\")\n",
    "df_interp.to_excel(output_excel, index=False)\n",
    "df_interp.to_parquet(output_parquet, index=False)\n",
    "\n",
    "print(f\"✅ Archivos exportados:\\n- {output_csv}\\n- {output_excel}\\n- {output_parquet}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da650e67-9fc6-45dd-a64e-f6535b9e08ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
